{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "257cf0b6",
   "metadata": {},
   "source": [
    "After analyzing the data, we opted for this strategy:\n",
    "\n",
    "**Proposed Strategy:**\n",
    "The test set will have exactly 2 records from the \"ISLAND\" category. The remaining test data (to complete ≈20% of the dataset) will be obtained through stratified sampling based on income_cat (median_income bins). This ensures 1) income representativeness – the most explanatory variable – and 2) at least some ISLAND examples to verify how the model extrapolates.\n",
    "\n",
    "**How to implement (conceptually):**\n",
    "1. Separate the 5 ISLAND rows\n",
    "   - Define `is_island = df.ocean_proximity == \"ISLAND\"`\n",
    "   - Keep 3 rows in training, 2 in the test \"pool\" (choose via fixed seed for reproducibility)\n",
    "\n",
    "2. Create income_cat in the NON-ISLAND subset\n",
    "   - Suggested bins from the book: [0–1.5, 1.5–3, 3–4.5, 4.5–6, > 6]\n",
    "   - This generates 5 relatively balanced strata\n",
    "\n",
    "3. Apply StratifiedShuffleSplit (test_size = 0.20) only to this non-ISLAND block\n",
    "   - Use fixed random_state\n",
    "   - Obtain train_idx, test_idx\n",
    "\n",
    "4. Combine\n",
    "   - Final test = test_idx rows + the 2 ISLAND rows\n",
    "   - Final training = train_idx rows + the remaining 3 ISLAND rows\n",
    "\n",
    "5. Verify proportions\n",
    "   - Calculate income_cat percentages in full dataset vs. new test (Δ ≤ 3 p.p.)\n",
    "   - Confirm that all 5 ocean_proximity categories now appear: <1H OCEAN, INLAND, NEAR OCEAN, NEAR BAY, ISLAND (2 rows)\n",
    "\n",
    "**Documentation:**\n",
    "Write in README: \"Hold-out contains 2/5 ISLAND rows (40%) due to sample scarcity; remaining 98% of hold-out generated via stratification by income_cat.\"\n",
    "\n",
    "**Benefits:**\n",
    "- Test set reflects income distribution, which explains ~70% of price variation\n",
    "- At least two \"ISLAND\" examples allow checking error in this class without unbalancing global metrics\n",
    "- Training still has 3 ISLAND rows, reducing extrapolation risk without reference\n",
    "\n",
    "**Limitation:**\n",
    "- ISLAND-specific metrics remain volatile (N=2), but already provide an indication\n",
    "- If ISLAND records increase in the future, simply reapply the same rule (40% in test; stratification in the rest)\n",
    "\n",
    "If this meets your requirements, simply follow this procedure when building the hold-out.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "986696dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Iniciando divisão do dataset Housing...\n",
      "📁 Carregando: /Users/marcelosilva/Desktop/Hands-on Machine Learning/data/processed/housing/housing_with_uid.csv\n",
      "✅ Dataset carregado: 20640 registros\n",
      "✅ Colunas básicas presentes\n",
      "🔧 income_cat será criada a partir de median_income\n",
      "📊 Dataset original: 20640 registros\n",
      "🏝️  Registros ISLAND: 5\n",
      "\n",
      "🔧 Criando categorias de renda...\n",
      "🔧 Usando coluna: median_income\n",
      "💰 Categorias de renda criadas:\n",
      "income_cat\n",
      "1     822\n",
      "2    6581\n",
      "3    7236\n",
      "4    3639\n",
      "5    2362\n",
      "Name: count, dtype: int64\n",
      "\n",
      "🔄 Processando splits...\n",
      "\n",
      "🔍 VALIDAÇÃO DO SPLIT:\n",
      "==================================================\n",
      "Dataset original: 20,640\n",
      "Train set: 16,418 (79.5%)\n",
      "Test set: 4,222 (20.5%)\n",
      "\n",
      "🏝️  ISLAND:\n",
      "Original: 5\n",
      "Train: 3\n",
      "Test: 2 ✓\n",
      "\n",
      "💰 ESTRATIFICAÇÃO INCOME_CAT (não-ISLAND):\n",
      "❌ Coluna income_cat não encontrada nos datasets\n",
      "\n",
      "🌊 OCEAN_PROXIMITY (todas as categorias presentes?):\n",
      "✅ Todas as categorias presentes no test set\n",
      "\n",
      "💾 DATASETS SALVOS:\n",
      "📁 Train: /Users/marcelosilva/Desktop/Hands-on Machine Learning/data/processed/housing/housing_train.csv\n",
      "📁 Test: /Users/marcelosilva/Desktop/Hands-on Machine Learning/data/processed/housing/housing_test.csv\n",
      "\n",
      "🎯 PRÓXIMOS PASSOS:\n",
      "1. Use APENAS housing_train.csv para desenvolvimento\n",
      "2. Mantenha housing_test.csv INTOCÁVEL até avaliação final\n",
      "3. Para validação durante desenvolvimento, faça split do train set\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import hashlib\n",
    "import numpy as np\n",
    "\n",
    "def create_stratified_test_set_by_uid(df, test_ratio=0.2, stratify_col='income_cat'):\n",
    "    \"\"\"\n",
    "    Split determinístico por UID + estratificado por income_cat\n",
    "    \"\"\"\n",
    "    test_indices = []\n",
    "    \n",
    "    for stratum in df[stratify_col].unique():\n",
    "        stratum_df = df[df[stratify_col] == stratum]\n",
    "        \n",
    "        # Hash determinístico dentro do estrato\n",
    "        def is_in_test_set(uid):\n",
    "            hash_val = int(hashlib.md5(str(uid).encode()).hexdigest()[-2:], 16)\n",
    "            return hash_val < (test_ratio * 256)  # ~20% dos hash values\n",
    "        \n",
    "        stratum_test = stratum_df[stratum_df['uid'].apply(is_in_test_set)]\n",
    "        test_indices.extend(stratum_test.index.tolist())\n",
    "    \n",
    "    test_df = df.loc[test_indices]\n",
    "    train_df = df.drop(test_indices)\n",
    "    \n",
    "    return test_df, train_df\n",
    "\n",
    "def island_train_test_split(island_df):\n",
    "    \"\"\"\n",
    "    Força exatamente 2 registros ISLAND para teste (determinístico por UID)\n",
    "    \"\"\"\n",
    "    sorted_uids = sorted(island_df['uid'].values)\n",
    "    test_uids = sorted_uids[:2]  # Sempre os mesmos 2 UIDs menores\n",
    "    \n",
    "    island_test = island_df[island_df['uid'].isin(test_uids)]\n",
    "    island_train = island_df[~island_df['uid'].isin(test_uids)]\n",
    "    \n",
    "    return island_test, island_train\n",
    "\n",
    "def create_income_categories(df):\n",
    "    \"\"\"\n",
    "    Cria categorias de renda como no livro do Géron\n",
    "    Bins: [0, 1.5, 3.0, 4.5, 6.0, inf]\n",
    "    \"\"\"\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Verificar se a coluna de renda existe\n",
    "    income_col = None\n",
    "    if 'median_income' in df.columns:\n",
    "        income_col = 'median_income'\n",
    "    elif 'medianIncome' in df.columns:\n",
    "        income_col = 'medianIncome'\n",
    "    else:\n",
    "        raise ValueError(\"Coluna de renda não encontrada. Esperado: 'median_income' ou 'medianIncome'\")\n",
    "    \n",
    "    print(f\"🔧 Usando coluna: {income_col}\")\n",
    "    \n",
    "    # Criar bins de renda (como no livro)\n",
    "    df['income_cat'] = pd.cut(df[income_col],\n",
    "                              bins=[0., 1.5, 3.0, 4.5, 6.0, np.inf],\n",
    "                              labels=[1, 2, 3, 4, 5])\n",
    "    \n",
    "    print(\"💰 Categorias de renda criadas:\")\n",
    "    print(df['income_cat'].value_counts().sort_index())\n",
    "    \n",
    "    return df\n",
    "\n",
    "def create_final_datasets(df, test_ratio=0.2):\n",
    "    \"\"\"\n",
    "    Cria datasets train/test com:\n",
    "    - ISLAND: força 2 para teste (40%)\n",
    "    - Resto: estratificação por income_cat + determinístico por UID\n",
    "    \"\"\"\n",
    "    print(f\"📊 Dataset original: {len(df)} registros\")\n",
    "    print(f\"🏝️  Registros ISLAND: {len(df[df['ocean_proximity'] == 'ISLAND'])}\")\n",
    "    \n",
    "    # 0. Criar categorias de renda se não existir\n",
    "    if 'income_cat' not in df.columns:\n",
    "        print(\"\\n🔧 Criando categorias de renda...\")\n",
    "        df = create_income_categories(df)\n",
    "    \n",
    "    # 1. Separar ISLAND do resto\n",
    "    island_df = df[df['ocean_proximity'] == 'ISLAND']\n",
    "    non_island_df = df[df['ocean_proximity'] != 'ISLAND']\n",
    "    \n",
    "    print(f\"\\n🔄 Processando splits...\")\n",
    "    \n",
    "    # 2. ISLAND: sempre 2 para teste\n",
    "    island_test, island_train = island_train_test_split(island_df)\n",
    "    \n",
    "    # 3. NÃO-ISLAND: estratificação por income_cat + UID\n",
    "    non_island_test, non_island_train = create_stratified_test_set_by_uid(\n",
    "        non_island_df, \n",
    "        test_ratio=test_ratio, \n",
    "        stratify_col='income_cat'\n",
    "    )\n",
    "    \n",
    "    # 4. Combinar datasets finais\n",
    "    final_test = pd.concat([non_island_test, island_test], ignore_index=True)\n",
    "    final_train = pd.concat([non_island_train, island_train], ignore_index=True)\n",
    "    \n",
    "    return final_train, final_test\n",
    "\n",
    "def validate_split(original_df, train_df, test_df):\n",
    "    \"\"\"\n",
    "    Valida se o split manteve as proporções corretas\n",
    "    \"\"\"\n",
    "    print(\"\\n🔍 VALIDAÇÃO DO SPLIT:\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    # Tamanhos\n",
    "    print(f\"Dataset original: {len(original_df):,}\")\n",
    "    print(f\"Train set: {len(train_df):,} ({len(train_df)/len(original_df)*100:.1f}%)\")\n",
    "    print(f\"Test set: {len(test_df):,} ({len(test_df)/len(original_df)*100:.1f}%)\")\n",
    "    \n",
    "    # ISLAND específico\n",
    "    island_original = len(original_df[original_df['ocean_proximity'] == 'ISLAND'])\n",
    "    island_train = len(train_df[train_df['ocean_proximity'] == 'ISLAND'])\n",
    "    island_test = len(test_df[test_df['ocean_proximity'] == 'ISLAND'])\n",
    "    \n",
    "    print(f\"\\n🏝️  ISLAND:\")\n",
    "    print(f\"Original: {island_original}\")\n",
    "    print(f\"Train: {island_train}\")\n",
    "    print(f\"Test: {island_test} ✓\" if island_test == 2 else f\"Test: {island_test} ❌\")\n",
    "    \n",
    "    # Estratificação income_cat (apenas no subconjunto não-ISLAND)\n",
    "    print(f\"\\n💰 ESTRATIFICAÇÃO INCOME_CAT (não-ISLAND):\")\n",
    "    \n",
    "    try:\n",
    "        original_non_island = original_df[original_df['ocean_proximity'] != 'ISLAND']\n",
    "        test_non_island = test_df[test_df['ocean_proximity'] != 'ISLAND']\n",
    "        \n",
    "        if 'income_cat' in original_non_island.columns and 'income_cat' in test_non_island.columns:\n",
    "            orig_props = original_non_island['income_cat'].value_counts(normalize=True).sort_index()\n",
    "            test_props = test_non_island['income_cat'].value_counts(normalize=True).sort_index()\n",
    "            \n",
    "            for cat in orig_props.index:\n",
    "                orig_pct = orig_props[cat] * 100\n",
    "                test_pct = test_props.get(cat, 0) * 100 if cat in test_props.index else 0\n",
    "                diff = abs(orig_pct - test_pct)\n",
    "                status = \"✓\" if diff <= 3.0 else \"⚠️\"\n",
    "                print(f\"Categoria {cat}: Original {orig_pct:.1f}% → Test {test_pct:.1f}% (Δ{diff:.1f}p.p.) {status}\")\n",
    "        else:\n",
    "            print(\"❌ Coluna income_cat não encontrada nos datasets\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro na validação income_cat: {e}\")\n",
    "        print(\"🔧 Verificando colunas disponíveis...\")\n",
    "        print(f\"Original: {original_df.columns.tolist()}\")\n",
    "        print(f\"Test: {test_df.columns.tolist()}\")\n",
    "    \n",
    "    # Ocean proximity geral\n",
    "    print(f\"\\n🌊 OCEAN_PROXIMITY (todas as categorias presentes?):\")\n",
    "    test_categories = set(test_df['ocean_proximity'].unique())\n",
    "    original_categories = set(original_df['ocean_proximity'].unique())\n",
    "    missing = original_categories - test_categories\n",
    "    \n",
    "    if len(missing) == 0:\n",
    "        print(\"✅ Todas as categorias presentes no test set\")\n",
    "    else:\n",
    "        print(f\"❌ Categorias ausentes no test: {missing}\")\n",
    "\n",
    "# ==================================================\n",
    "# EXECUÇÃO PRINCIPAL\n",
    "# ==================================================\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Carregar dataset\n",
    "    file_path = \"/Users/marcelosilva/Desktop/Hands-on Machine Learning/data/processed/housing/housing_with_uid.csv\"\n",
    "    \n",
    "    print(\"🚀 Iniciando divisão do dataset Housing...\")\n",
    "    print(f\"📁 Carregando: {file_path}\")\n",
    "    \n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(f\"✅ Dataset carregado: {len(df)} registros\")\n",
    "        \n",
    "        # Verificar se colunas básicas existem\n",
    "        income_col = 'median_income' if 'median_income' in df.columns else 'medianIncome'\n",
    "        required_cols = ['uid', income_col, 'ocean_proximity']\n",
    "        missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "        \n",
    "        if missing_cols:\n",
    "            print(f\"❌ Colunas ausentes: {missing_cols}\")\n",
    "            print(f\"📋 Colunas disponíveis: {list(df.columns)}\")\n",
    "        else:\n",
    "            print(f\"✅ Colunas básicas presentes\")\n",
    "            print(f\"🔧 income_cat será criada a partir de {income_col}\")\n",
    "            \n",
    "            # Criar splits\n",
    "            train_dataset, test_dataset = create_final_datasets(df, test_ratio=0.2)\n",
    "            \n",
    "            # Validar splits\n",
    "            validate_split(df, train_dataset, test_dataset)\n",
    "            \n",
    "            # Salvar datasets\n",
    "            output_dir = \"/Users/marcelosilva/Desktop/Hands-on Machine Learning/data/processed/housing/\"\n",
    "            train_path = output_dir + \"housing_train.csv\"\n",
    "            test_path = output_dir + \"housing_test.csv\"\n",
    "            \n",
    "            train_dataset.to_csv(train_path, index=False)\n",
    "            test_dataset.to_csv(test_path, index=False)\n",
    "            \n",
    "            print(f\"\\n💾 DATASETS SALVOS:\")\n",
    "            print(f\"📁 Train: {train_path}\")\n",
    "            print(f\"📁 Test: {test_path}\")\n",
    "            print(f\"\\n🎯 PRÓXIMOS PASSOS:\")\n",
    "            print(f\"1. Use APENAS housing_train.csv para desenvolvimento\")\n",
    "            print(f\"2. Mantenha housing_test.csv INTOCÁVEL até avaliação final\")\n",
    "            print(f\"3. Para validação durante desenvolvimento, faça split do train set\")\n",
    "            \n",
    "    except FileNotFoundError:\n",
    "        print(f\"❌ Arquivo não encontrado: {file_path}\")\n",
    "        print(\"Verifique se o caminho está correto.\")\n",
    "    except Exception as e:\n",
    "        print(f\"❌ Erro: {e}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
